{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2a4e25",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2005af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73de04",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d9dd8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9818fb3beed0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtestdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtraindata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.csv'"
     ]
    }
   ],
   "source": [
    "testdata = pd.read_csv('test.csv')\n",
    "traindata = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dba5b4a",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "1)Analysis of the features.\n",
    "\n",
    "2)Finding any relations or trends considering multiple features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbecac",
   "metadata": {},
   "source": [
    "Understanding the data we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e7d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7f984",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traindata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433edff",
   "metadata": {},
   "source": [
    "Checking for any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf30bb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traindata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91118ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c781ac8d",
   "metadata": {},
   "source": [
    "Dropping duplicates from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d401a32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traindata.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7648e",
   "metadata": {},
   "source": [
    "Overall survival rate of the passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f11abd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x =traindata['Survived'])\n",
    "survived=float(traindata[traindata['Survived']==1]['Survived'].count()/traindata[['Survived']].count())*100\n",
    "print(str(round(survived,2))+'% survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72701efa",
   "metadata": {},
   "source": [
    "# Nominal data\n",
    "\n",
    "(Only 2 classes) Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ed810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "survived_by_gender = traindata.groupby(['Sex','Survived'])['Survived'].count()\n",
    "survival_rate_by_gender = pd.Series({'female': survived_by_gender[1]/(survived_by_gender[0]+survived_by_gender[1]), \n",
    "                           'male': survived_by_gender[3]/(survived_by_gender[2]+survived_by_gender[3])})\n",
    "\n",
    "print(survived_by_gender, '\\n')\n",
    "print(survival_rate_by_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8ac1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "sns.countplot(ax=ax[0], x=\"Survived\",data=traindata,hue=\"Sex\")\n",
    "ax[0].set_title('Survived Individuals by Sex')\n",
    "\n",
    "survival_rate_by_gender.plot.bar(ax=ax[1])\n",
    "ax[1].set_title('Survival Rate by Sex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4c739",
   "metadata": {},
   "source": [
    "Encoding gender into binary values, male being 1 and 0 being female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70261744",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = [traindata, testdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in combine:\n",
    "    data['Sex'] = data['Sex'].replace(['male','female'],[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abfef13",
   "metadata": {},
   "source": [
    "# Ordinal data\n",
    "\n",
    "Pclass, Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f776a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for data in combine:\n",
    "    data.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)\n",
    "    \n",
    "traindata.drop('PassengerId',axis=1,inplace=True)\n",
    "    \n",
    "traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ada3b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Pclass',data = traindata, hue='Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fd9ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survival_rate_by_pclass = traindata.groupby(['Pclass'])['Survived'].mean()\n",
    "\n",
    "print(survival_rate_by_pclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed33ae24",
   "metadata": {},
   "source": [
    "From the results above, we can see that Passenger Class 1 has the highest chance of survival of 63%, followed by Passenger Class 2 with 47% and finally Passenger Class 3 with only 24%. Next, we will take a look at how gender affects the survival rate of top of the Passenger Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5828e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "survival_rate_pclass_sex=traindata.groupby(['Pclass','Sex'])['Survived'].mean()\n",
    "survival_rate_pclass_sex.unstack().plot.bar()\n",
    "\n",
    "survival_rate_pclass_sex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d899e",
   "metadata": {},
   "source": [
    "From the data above, we can conclude that most female passengers in Pclass 1 have survived. Whereas male passengers in Pclass have the lowest survival rate of all at only 13.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86124565",
   "metadata": {},
   "source": [
    "## Embarked\n",
    "\n",
    "Titanic had embarked in order of, S = Southampton, C = Cherbourg (France), and Q = Queenstown (Ireland). \n",
    "\n",
    "Ref: https://web.archive.org/web/20120415195436/http://www.chriscunard.com/titanic.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549df625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embarked = traindata.groupby(['Embarked'])['Survived'].mean()\n",
    "\n",
    "embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa10a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embarked.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c4d64",
   "metadata": {},
   "source": [
    "From the percentages above, we see that passengers embarked from Southampton have a quite significant difference from the other passengers. Let's take a look at the total passenger embarking from Southampton to see that will give us an idea why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985b570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survived_em = traindata.groupby('Embarked')['Survived'].sum()\n",
    "passnum = traindata.groupby('Embarked')['Survived'].count()\n",
    "\n",
    "print(survived_em, passnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69a0f9",
   "metadata": {},
   "source": [
    "Breaking down the survival rate into the total passengers and the survived passengers do not provide us with any clear reason why too. Let's take a look at the other features according to the location embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c77f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindata.groupby('Embarked').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13fed2",
   "metadata": {},
   "source": [
    "Now from this table, we can see that the average passenger embarking from Cherbourg is paying a higher fare for higher passenger class seats than the passengers embarking from the other 2 location. This can be seen from the mean Pclass of the passengers being closer to the First Class, which explains why they have a higher survival rate compared to the other passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostemb = []\n",
    "\n",
    "for data in combine:\n",
    "    mostemb = data['Embarked'].dropna().mode()[0]\n",
    "    data['Embarked'] = data['Embarked'].fillna(mostemb)\n",
    "    data['Embarked'] = data['Embarked'].replace(['C','Q','S'],[0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98b78c",
   "metadata": {},
   "source": [
    "# Continouous Data\n",
    "\n",
    "Age, SibSp, Parch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702985b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(18,4))\n",
    "\n",
    "sns.histplot(ax=axes[0], x='Age', data=traindata, bins=10, hue='Survived')\n",
    "sns.countplot(ax=axes[2], x='SibSp',data = traindata, hue='Survived')\n",
    "sns.countplot(ax=axes[1], x='Parch',data = traindata, hue='Survived')\n",
    "\n",
    "ax[0].set_title('Survived vs Sex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d68730",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "children = traindata[traindata['Age']<=19]\n",
    "adults = traindata[(traindata['Age']>19) & (traindata['Age']<60)]\n",
    "senior = traindata[traindata['Age']>=60]\n",
    "\n",
    "age_groups = [children['Survived'].mean(), adults['Survived'].mean(), senior['Survived'].mean()]\n",
    "y = ['Children', 'Adults', 'Seniors']\n",
    "\n",
    "print(type(age_groups))\n",
    "\n",
    "plt.bar(y, age_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d69150",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo = traindata[(traindata['Parch']==0) & (traindata['SibSp']==0)]\n",
    "\n",
    "mean_solo = solo['Age'].mean()\n",
    "\n",
    "solo_pct = solo['Survived'].mean()\n",
    "\n",
    "print('Solo passengers (mean age: {:}) without siblings/spouse or parents/children only have {:.2f}% of survival'.format(int(mean_solo),solo_pct*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf93f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=traindata['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in combine:\n",
    "    medianage = data['Age'].dropna().median()\n",
    "    data['Age'] = data['Age'].fillna(medianage)\n",
    "    \n",
    "    data['Age_band']=0\n",
    "    data.loc[data['Age']<=19,'Age_band']=0\n",
    "    data.loc[(data['Age']>19)&(data['Age']<60),'Age_band']=1\n",
    "    data.loc[data['Age']>=60,'Age_band']=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92f8c2",
   "metadata": {},
   "source": [
    "## Fare \n",
    "\n",
    "This feature is closely related to the passenger class on Titanic as the higher class the seat is the more expensive it is.\n",
    "\n",
    "\"A third class ticket cost around £7 in 1912 which is nearly £800 in today's money. A second class ticket cost around £13 or nearly £1500 today and a first class ticket would have set you back a minimum of £30 or more than £3300 today.\" \n",
    "\n",
    "Ref: https://www.bbc.co.uk/bitesize/topics/z8mpfg8/articles/zng8jty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938fb2fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(16,4))\n",
    "\n",
    "# Set the scale of the x-and y-axes\n",
    "ax[1].set(yscale=\"log\")\n",
    "ax[0].set_title('Count vs Fare plot')\n",
    "ax[1].set_title('Logarithmic Count vs Fare plot')\n",
    "\n",
    "sns.histplot(ax=ax[0], x='Fare',data = traindata, hue='Survived', bins = 10, multiple = 'dodge')\n",
    "sns.histplot(ax=ax[1],x='Fare',data = traindata, hue='Survived', bins = 10, multiple = 'dodge')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8763197",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "third_mean = round(traindata[traindata['Fare']<13]['Survived'].mean(),3)\n",
    "second_mean = round(traindata[(traindata['Fare']>=13) & (traindata['Fare']<30)]['Survived'].mean(),3)\n",
    "first_mean = round(traindata[traindata['Fare']>=30]['Survived'].mean(),3)\n",
    "\n",
    "labels = ['Third Class Fare', 'Second Class Fare', 'First Class Fare']\n",
    "\n",
    "plt.plot(labels,[third_mean, second_mean, first_mean],marker='o')\n",
    "plt.title('Survival Rate of The Passengers by The Fare Paid')\n",
    "\n",
    "for i, v in enumerate([third_mean, second_mean, first_mean]):\n",
    "    plt.annotate(str(v), xy=(i,v), xytext=(5,0), textcoords='offset points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff78c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in combine:\n",
    "    medianfare = data['Fare'].dropna().median()\n",
    "    data['Fare'] = data['Fare'].fillna(medianage)\n",
    "    \n",
    "    data['Fare_band']=0\n",
    "    data.loc[data['Fare']<=13,'Fare_band']=0\n",
    "    data.loc[(data['Fare']>13)&(data['Fare']<30),'Fare_band']=1\n",
    "    data.loc[data['Fare']>=30,'Fare_band']=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a298e0",
   "metadata": {},
   "source": [
    "# Correlation Plot\n",
    "\n",
    "Finding out the correlation to the survival of the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f997e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data in combine:\n",
    "    data.drop(['Fare','Age'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af026a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = traindata.corr()\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(c,vmin = -1,vmax = 1, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa3c93",
   "metadata": {},
   "source": [
    "# Training and testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required ML packages\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[]\n",
    "X_train = traindata.drop(\"Survived\", axis=1)\n",
    "Y_train = traindata[\"Survived\"]\n",
    "X_test  = testdata.drop('PassengerId',axis=1).copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9261fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred_lr = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "score.append(acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector classification\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred_svc = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "score.append(acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c0632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-nearest neighbour\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "score.append(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd28f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian naive-bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred_gnb = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "score.append(acc_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred_perceptron = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "score.append(acc_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear support vector classification\n",
    "\n",
    "linear_svc = LinearSVC(dual = False)\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "Y_pred_linsvc = linear_svc.predict(X_test)\n",
    "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n",
    "score.append(acc_linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae76a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochastic gradient descent classifier\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred_sgd = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "score.append(acc_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b880b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred_dtree = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "score.append(acc_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred_rf = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "score.append(acc_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': score})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7cce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": testdata[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred_linsvc\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74507dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc.predict([[3,1,0,0,1,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdde6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"linear_svc.pkl\",\"wb\")\n",
    "pickle.dump(linear_svc, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d8745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
